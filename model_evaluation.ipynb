{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "65c07508",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c09645ff",
   "metadata": {},
   "source": [
    "## Imports & settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98cb1540",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "import json\n",
    "import shap\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import norm\n",
    "from pathlib import Path\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "from tensorflow.keras.models import load_model\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ab33230",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Asset, quantile, model and target selection\n",
    "symbol = \"BTC\"\n",
    "quantile = \"01_99\"\n",
    "trial_id = 5\n",
    "target = \"log_returns_7\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a6054b1",
   "metadata": {},
   "source": [
    "## Data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d7b80f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_market_data(path: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Given a path to a file about an asset market data in CSV format, returns a pandas dataframe with the data,\n",
    "    sorted by time dimension in ascending order.\n",
    "    \"\"\"\n",
    "    # Reads file\n",
    "    df = pd.read_csv(path, header=0, sep=',', parse_dates=True)\n",
    "\n",
    "    # Sets date as index\n",
    "    df.set_index('date', inplace=True)\n",
    "\n",
    "    # Sorts the dataframe ascending by date\n",
    "    df.sort_index(inplace=True)\n",
    "    \n",
    "    return df\n",
    "\n",
    "market_data_path = Path(f\"market_data/{symbol}.csv\")\n",
    "market_data = read_market_data(market_data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5673e221",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loads the test set features\n",
    "X_test = pd.read_csv(Path(f\"derived_data/{symbol}/X_test.csv\"))\n",
    "X_test = X_test.set_index('date')\n",
    "\n",
    "# Loads the test set targets\n",
    "y_test = pd.read_csv(Path(f\"data/split/{symbol}/y_test.csv\"))\n",
    "y_test = y_test.set_index('date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e71ff87e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieves the model's architecture\n",
    "architecture_path = Path(f\"architectures/{symbol}/{quantile}/{trial_id}.json\")\n",
    "\n",
    "# Loads the architecture JSON file\n",
    "with open(architecture_path, \"r\") as f:\n",
    "    config = json.load(f)\n",
    "\n",
    "window_size = config.get(\"window size\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61abce5d",
   "metadata": {},
   "source": [
    "## Model loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d39d9463",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieves the model\n",
    "model_path = Path(f\"models/{symbol}/{quantile}/{trial_id}_{target}.h5\")\n",
    "\n",
    "# Loads the model\n",
    "model = load_model(model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cece06e",
   "metadata": {},
   "source": [
    "## Performance metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2255ed0",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "\n",
    "# Retrieves related performance metrics\n",
    "validation_performance_path = Path(f\"logs/{symbol}/performance/validation/{quantile}/{trial_id}_{target}.csv\")\n",
    "test_performance_path = Path(f\"logs/{symbol}/performance/test/{quantile}/generalization.csv\")\n",
    "\n",
    "# Loads model performance metrics\n",
    "validation_df = pd.read_csv(validation_performance_path)\n",
    "\n",
    "test_df = pd.read_csv(test_performance_path)\n",
    "test_row = test_df[(test_df[\"trial_id\"] == trial_id) & (test_df[\"target\"] == target)].iloc[0]\n",
    "\n",
    "# Aligns step axis (assumes validation is yearly)\n",
    "validation_df[\"year\"] = validation_df[\"step\"] // 365\n",
    "test_point_x = validation_df[\"year\"].max()\n",
    "\n",
    "# Defines the rolling metrics to plot\n",
    "metrics = [\"sharpe\", \"max_drawdown\", \"cumulative_return\", \"volatility\"]\n",
    "titles = [\"Sharpe Ratio\", \"Max Drawdown\", \"Cumulative Return\", \"Volatility\"]\n",
    "\n",
    "plt.figure(figsize=(14, 10))\n",
    "\n",
    "for i, metric in enumerate(metrics):\n",
    "    plt.subplot(2, 2, i+1)\n",
    "\n",
    "    # Copy validation data and append test point\n",
    "    combined_years = list(validation_df[\"year\"]) + [validation_df[\"year\"].max() + 1]\n",
    "    combined_values = list(validation_df[metric]) + [test_row[metric]]\n",
    "\n",
    "    # Plots validation\n",
    "    plt.plot(combined_years, combined_values, marker='o', label=\"Validation\")\n",
    "\n",
    "    # Highlights test point with a special marker\n",
    "    plt.scatter(combined_years[-1], combined_values[-1], color='orange', edgecolors='black', zorder=5, s=80, label=\"Test\")\n",
    "\n",
    "    # Labels and title\n",
    "    plt.title(titles[i])\n",
    "    plt.xlabel(\"Year\")\n",
    "    plt.tight_layout()\n",
    "    plt.grid(True)\n",
    "    plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f40b8f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reshape_data(X, y, window_size):\n",
    "    \"\"\"\n",
    "    Reshapes the datasets into input sequences and corresponding targets required for the model.\n",
    "    \"\"\"\n",
    "    # Converts the dataframes to numpy arrays\n",
    "    if isinstance(X, (pd.DataFrame, pd.Series)): X = X.values\n",
    "    if isinstance(y, (pd.DataFrame, pd.Series)): y = y.values\n",
    "\n",
    "    X_seq, y_seq = [], []\n",
    "\n",
    "    for i in range(len(X) - window_size):\n",
    "        X_seq.append(X[i:i+window_size])\n",
    "        y_seq.append(y[i + window_size])\n",
    "\n",
    "    return np.array(X_seq), np.array(y_seq)\n",
    "\n",
    "# Keeps feature names\n",
    "feature_names = X_test.columns\n",
    "\n",
    "# Reshapes data\n",
    "X_test_seq, y_test_seq = reshape_data(X_test, y_test[target], int(window_size))\n",
    "y_true = pd.DataFrame(y_test_seq, columns=[target], index=y_test.index[int(window_size):])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0726113",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluates generalization on test set\n",
    "y_pred = model.predict(X_test_seq, verbose=0)\n",
    "y_pred = pd.DataFrame(y_pred, columns=[target], index=y_true.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54ddf618",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plots a scatter plot of the predictions vs the ground truth values\n",
    "plt.figure(figsize=(15, 5))\n",
    "plt.scatter(y_pred, y_true, alpha=0.5)\n",
    "plt.title('Predictions vs labels')\n",
    "plt.xlabel('Predictions')\n",
    "plt.ylabel('Labels')\n",
    "plt.tight_layout()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee80f75f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_sharpe(y_true: pd.DataFrame, y_pred: pd.DataFrame, lower_q: float, upper_q: float) -> tuple:\n",
    "    \"\"\"\n",
    "    Given the true, predicted values of test set, the lower and upper quantiles that define position\n",
    "    direction, this function calculates the sharpe ratio of the strategy (model) and the probabilistic\n",
    "    sharpe ratio. Returns the sharpe ratio, the probabilistic sharpe ratio, number of long and short \n",
    "    trades, and cumulative returns of both positions.\n",
    "    \"\"\"\n",
    "    # Calculates the quantiles of the strategy predicted values\n",
    "    s_thresh = np.quantile(y_pred, lower_q)\n",
    "    l_thresh = np.quantile(y_pred, upper_q)\n",
    "\n",
    "    # Calculates the direction of the positions based on the quantile thresholds\n",
    "    s_mask = y_pred <= s_thresh\n",
    "    l_mask = y_pred >= l_thresh\n",
    "\n",
    "    # Calculates the returns of the strategy based on the true values\n",
    "    s_returns = (np.exp(y_true[s_mask].dropna()) - 1).values\n",
    "    l_returns = (np.exp(y_true[l_mask].dropna()) - 1).values\n",
    "    s_returns = -s_returns  # short position returns\n",
    "    all_returns = np.concatenate([s_returns, l_returns])\n",
    "\n",
    "    # Calculates the sharpe ratio of the strategy\n",
    "    sharpe = np.mean(all_returns) / np.std(all_returns, ddof=1)\n",
    "\n",
    "    # Calculates the probabilistic sharpe ratio\n",
    "    std_error = np.sqrt((1 + 0.5 * sharpe**2) / len(all_returns))\n",
    "    benchmark = 0  # Assuming a benchmark of 0 for simplicity\n",
    "    z = (sharpe - benchmark) / std_error\n",
    "\n",
    "    return sharpe, norm.cdf(z), len(s_returns), len(l_returns), np.prod(1 + l_returns) - 1, np.prod(1 + s_returns) - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a944110",
   "metadata": {},
   "outputs": [],
   "source": [
    "lq, uq = ast.literal_eval(test_row[\"quantiles\"])\n",
    "sharpe, psr, n_s, n_l, cum_l, cum_s = calculate_sharpe(y_true, y_pred, lq, uq)\n",
    "# (How much do I make when I am right?)\n",
    "print(f\"Sharpe: {sharpe:.4f} | Significance: {psr:.4f} | Long positions: {n_l} | Short positions: {n_s}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "802d935f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "\n",
    "# Aligns price and prediction series\n",
    "price = market_data['close']\n",
    "price = price.loc[y_pred.index]\n",
    "y_pred = y_pred[target]\n",
    "\n",
    "# Calculates thresholds\n",
    "s_thresh = np.quantile(y_pred, lq)\n",
    "l_thresh = np.quantile(y_pred, uq)\n",
    "\n",
    "# Defines signal masks\n",
    "s_mask = y_pred <= s_thresh\n",
    "l_mask = y_pred >= l_thresh\n",
    "\n",
    "# Converts to numpy arrays for efficient indexing\n",
    "dates = price.index.to_numpy()\n",
    "prices = price.values\n",
    "\n",
    "# Plot with colored line segments\n",
    "horizon = 7  # Forward steps of the prediction\n",
    "\n",
    "plt.figure(figsize=(14, 6))\n",
    "\n",
    "# 1. Plot full BTC price line in light black/gray for context\n",
    "plt.plot(dates, prices, color='black', linewidth=1.5, label='BTC Price')\n",
    "\n",
    "# 2. Overlay colored signal-based segments for horizon\n",
    "for i in range(len(price) - horizon):\n",
    "    color = None\n",
    "    if l_mask.iloc[i]:\n",
    "        color = 'green'\n",
    "    elif s_mask.iloc[i]:\n",
    "        color = 'red'\n",
    "\n",
    "    if color:\n",
    "        # Plot forward horizon segment\n",
    "        plt.plot(dates[i:i + horizon + 1], prices[i:i + horizon + 1], color=color, linewidth=2)\n",
    "\n",
    "# Improve x-axis\n",
    "plt.xticks(rotation=45)\n",
    "plt.gca().xaxis.set_major_locator(plt.MaxNLocator(12))\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.title('BTC Price with Strategy Signals as Colored Segments')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Price')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5628fc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert boolean masks to int: 1 when a position opens\n",
    "mask = (s_mask | l_mask).astype(int).values  # Combined signal mask\n",
    "position_lifetime = 7\n",
    "\n",
    "# Initialize array to count active positions\n",
    "open_positions = np.zeros(len(mask), dtype=int)\n",
    "\n",
    "# Accumulate open positions using a rolling window of 'position_lifetime'\n",
    "for i in range(len(mask)):\n",
    "    if mask[i] == 1:\n",
    "        end_idx = min(i + position_lifetime, len(mask))  # Avoid overflow\n",
    "        open_positions[i:end_idx] += 1\n",
    "\n",
    "# Convert to pandas Series for convenience\n",
    "open_positions_series = pd.Series(open_positions, index=price.index)\n",
    "\n",
    "# Plot the number of open positions over time\n",
    "plt.figure(figsize=(14, 4))\n",
    "open_positions_series.plot()\n",
    "plt.title(f'Number of open positions')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Open positions')\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "311f88d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = y_true[target]\n",
    "\n",
    "# 1. Binary classification: 1 if predicted return > 0\n",
    "y_pred_bin = (y_pred > 0).astype(int)\n",
    "y_true_bin = (y_true > 0).astype(int)\n",
    "\n",
    "# 2. Evaluate directional accuracy\n",
    "precision = precision_score(y_true_bin, y_pred_bin)\n",
    "recall = recall_score(y_true_bin, y_pred_bin)\n",
    "f1 = f1_score(y_true_bin, y_pred_bin)\n",
    "conf_matrix = confusion_matrix(y_true_bin, y_pred_bin)\n",
    "\n",
    "# 3. Display results (How often am I right?)\n",
    "print(\"Directional Precision:\", round(precision, 3))\n",
    "print(\"Directional Recall:\", round(recall, 3))\n",
    "print(\"Directional F1 Score:\", round(f1, 3))\n",
    "print(\"Confusion Matrix:\\n\", conf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c400782",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute returns\n",
    "long_returns = (np.exp(y_true[l_mask]) - 1).values\n",
    "short_returns = -(np.exp(y_true[s_mask]) - 1).values  # inverse for shorts\n",
    "all_returns = np.concatenate([long_returns, short_returns])\n",
    "\n",
    "# Metrics\n",
    "cumulative_return = np.prod(1 + all_returns)\n",
    "volatility = np.std(all_returns, ddof=1)\n",
    "sharpe = np.mean(all_returns) / volatility\n",
    "\n",
    "equity_curve = np.cumprod(1 + all_returns)\n",
    "peak = np.maximum.accumulate(equity_curve)\n",
    "drawdown = (peak - equity_curve) / peak\n",
    "max_drawdown = np.max(drawdown)\n",
    "\n",
    "hit_ratio = np.mean(all_returns > 0)\n",
    "profit_factor = np.sum(all_returns[all_returns > 0]) / abs(np.sum(all_returns[all_returns < 0]))\n",
    "\n",
    "print(\"Sharpe:\", sharpe)\n",
    "print(\"Cumulative Return:\", cumulative_return)\n",
    "print(\"Volatility:\", volatility)\n",
    "print(\"Max Drawdown:\", max_drawdown)\n",
    "print(\"Hit Ratio:\", hit_ratio)\n",
    "print(\"Profit Factor:\", profit_factor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28eefa83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Reconstruct returns from log returns ---\n",
    "returns = pd.Series(0.0, index=y_true.index)  # Initialize returns with 0, aligned to dates\n",
    "returns.loc[l_mask] = (np.exp(y_true[l_mask]) - 1).values\n",
    "returns.loc[s_mask] = -(np.exp(y_true[s_mask]) - 1).values  # short returns are negative\n",
    "\n",
    "# --- Compute equity curve ---\n",
    "equity = (1 + returns).cumprod()  # start with 1 capital unit\n",
    "equity.index = pd.to_datetime(equity.index)  # ensure index is datetime\n",
    "\n",
    "# --- Plot ---\n",
    "plt.figure(figsize=(14, 6))\n",
    "plt.plot(equity.index, equity.values, label='Equity Curve', color='blue', linewidth=2)\n",
    "\n",
    "# Format x-axis with month-year\n",
    "ax = plt.gca()\n",
    "ax.xaxis.set_major_locator(mdates.AutoDateLocator())\n",
    "ax.xaxis.set_major_formatter(mdates.DateFormatter('%Y-%m'))\n",
    "\n",
    "# Final plot touches\n",
    "plt.xticks(rotation=45)\n",
    "plt.title('Model Strategy Equity Curve')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Capital ($)')\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c5c0e55",
   "metadata": {},
   "source": [
    "# Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4ec15f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decision threshold\n",
    "print(f\"Short decision threshold:\", s_thresh)\n",
    "print(f\"Long decision threshold:\", l_thresh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dec8dcf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_last_window(X, window_size):\n",
    "    \"\"\"\n",
    "    Extracts the last window of features from the test set for prediction.\n",
    "    \"\"\"\n",
    "    if isinstance(X, (pd.DataFrame, pd.Series)):\n",
    "        X = X.values\n",
    "    \n",
    "    last_window = X[-window_size:]\n",
    "\n",
    "    return np.expand_dims(last_window, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cce8580e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_last = get_last_window(X_test, int(window_size))\n",
    "y_last_pred = model.predict(X_last, verbose=0)\n",
    "print(\"Prediction:\", y_last_pred[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d61ae53d",
   "metadata": {},
   "outputs": [],
   "source": [
    "if y_last_pred < s_thresh:\n",
    "    print(\"Decision: Short\")\n",
    "elif y_last_pred > l_thresh:\n",
    "    print(\"Decision: Long\")\n",
    "else:\n",
    "    print(\"Decision: Neutral\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "491b15df",
   "metadata": {},
   "source": [
    "# Interpretation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c03120d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keeps the original shape of test data\n",
    "n_samples, window_size, n_features = X_test_seq.shape\n",
    "\n",
    "# Flattens input for SHAP (2D)\n",
    "X_flat = X_test_seq.reshape((n_samples, window_size * n_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f92726da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_fn(X_flat_input):\n",
    "    \"\"\"\n",
    "    Prediction wrapper, reshapes test data to fullfill shap requirements\n",
    "    \"\"\"\n",
    "    X_reshaped = X_flat_input.reshape((-1, window_size, n_features))\n",
    "    \n",
    "    return model.predict(X_reshaped, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad5c450a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reduce background size by randomly sampling K instances\n",
    "X_background_sampled = shap.sample(X_flat, 100)  # Adjust K as needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "027f24d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializes the explainer\n",
    "explainer = shap.KernelExplainer(predict_fn, X_background_sampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bde4f42d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Computes SHAP values\n",
    "# shap_values_flat = explainer.shap_values(X_background_sampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88f62e0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Reshapes the flattened SHAP values\n",
    "# shap_values_3d = shap_values_flat[0].reshape((-1, window_size, n_features))  # (samples, timesteps, features)\n",
    "\n",
    "# # Option A: Last timestep\n",
    "# shap_last = shap_values_3d[:, -1, :] # shape: (samples, features)\n",
    "# X_last = X_test_seq[:shap_last.shape[0], -1, :] # ensure alignment\n",
    "# shap.summary_plot(shap_last, X_last, feature_names=feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f5a57f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Option B: Mean absolute SHAP across time\n",
    "# shap_avg = np.mean(np.abs(shap_values_3d), axis=1) # shape: (samples, features)\n",
    "# shap.summary_plot(shap_avg, X_last, feature_names=feature_names)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "models",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
